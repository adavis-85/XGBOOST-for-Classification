{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f412233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:*******.csv')\n",
    "data = data.dropna()\n",
    "first_data_forchart=cp.deepcopy(data)\n",
    "\n",
    "target = data.pop('******')\n",
    "\n",
    "#splitting into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=2)\n",
    "\n",
    "##hyperparameter tuning\n",
    "xgb_model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "#listing parameters for searching grid \n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.3, 0.7),\n",
    "    \"gamma\": uniform(0.001,.5),\n",
    "    \"learning_rate\": uniform(.003,1),\n",
    "    \"max_depth\": [1,2,3,4,5,6,7], \n",
    "    \"n_estimators\": randint(100, 150), \n",
    "    \"subsample\": uniform(0.001,0.6),\n",
    "    \"min_child_weight\":uniform(0,10),\n",
    "    \"max_delta_step\":uniform(0,10),\n",
    "    \"reg_alpha\":uniform(0,.9),\n",
    "    \"reg_lambda\":uniform(1,4),\n",
    "    \"scale_pos_weight\":uniform(1,5),\n",
    "    \"tree_method\":['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "         }\n",
    "\n",
    "#searching best parameters\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, \n",
    "                            n_iter=200, random_state=42,cv=3, verbose=1, \n",
    "                            n_jobs=1, return_train_score=True)\n",
    "\n",
    "#training the model to find the optimal parameters\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "#set model with optimal parameters\n",
    "def tuned_hyper(search_results):\n",
    "    \n",
    "    #best params for shorter length later on\n",
    "    #in case of multiples\n",
    "    whole_array=np.where(search_results['rank_test_score']==1)\n",
    "    if len(whole_array[0])>1:\n",
    "        whole_array=np.where(search_results['rank_test_score']==1)[0]\n",
    "        \n",
    "    first_spot=int(whole_array[0])\n",
    "    winning_combo=search_results['params'][first_spot]\n",
    "    col_tree=winning_combo['colsample_bytree']\n",
    "    gams=winning_combo['gamma']\n",
    "    lr=winning_combo['learning_rate']\n",
    "    m_dep=winning_combo['max_depth']\n",
    "    nest=winning_combo['n_estimators']\n",
    "    s_samp=winning_combo['subsample']\n",
    "    min_ch=winning_combo['min_child_weight']\n",
    "    max_del=winning_combo['max_delta_step']\n",
    "    r_alpha=winning_combo['reg_alpha']\n",
    "    r_lambda=winning_combo['reg_lambda']\n",
    "    sc_posw=winning_combo['scale_pos_weight']\n",
    "    treem=winning_combo['tree_method']\n",
    "    \n",
    "    #setting the model up with best parameters\n",
    "    best_model= XGBClassifier(colsample_bytree=col_tree,\n",
    "                              gamma=gams,\n",
    "                              learning_rate=lr,\n",
    "                              max_depth=m_dep,\n",
    "                              n_estimators=nest, \n",
    "                              use_label_encoder=False,\n",
    "                              subsample=s_samp,\n",
    "                              min_child_weight=min_ch,\n",
    "                              max_delta_step=max_del,\n",
    "                              reg_alpha=r_alpha,\n",
    "                              reg_lambda=r_lambda,\n",
    "                              scale_pos_weight=sc_posw,\n",
    "                              tree_method=treem \n",
    "                             )\n",
    "    return best_model\n",
    "\n",
    "\n",
    "#function run\n",
    "a=tuned_hyper(search.cv_results_)\n",
    "\n",
    "#fitting best model\n",
    "a.fit(X_train, y_train)\n",
    "\n",
    "preds=a.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,preds)\n",
    "\n",
    "# predict probabilities on Test and take probability for class 1([:1])\n",
    "y_pred_prob_test = a.predict_proba(X_test)[:, 1]\n",
    "#predict labels on test dataset\n",
    "y_pred_test = preds\n",
    "# create onfusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "print(\"confusion Matrix is :nn\",cm)\n",
    "print(\"n\")\n",
    "# Accuracy \n",
    "print(\"Accuracy  test dataset:  t\", accuracy_score(y_test,y_pred_test))\n",
    "# ROC- AUC score\n",
    "print(\"ROC-AUC score  test dataset:  t\", metrics.roc_auc_score(y_test,y_pred_prob_test))\n",
    "#Precision score\n",
    "print(\"precision score  test dataset:  t\", metrics.precision_score(y_test,y_pred_test))#,average='micro'))\n",
    "#Recall Score\n",
    "print(\"Recall score  test dataset:  t\", metrics.recall_score(y_test,y_pred_test))\n",
    "#f1 score\n",
    "print(\"f1 score  test dataset :  t\", f1_score(y_test,y_pred_test))#,average='binary'))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,preds)\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "#to visualize the importance of each feature/column\n",
    "plot_importance(a)\n",
    "\n",
    "#measures several accuracy indicators\n",
    "print(classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
